{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "#from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction for cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show():\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "    \n",
    "def clean_format(w):\n",
    "    w = w.lower().replace('.', '').replace(',', '').replace('!', '')\n",
    "    #.replace('+', '').replace('(', '').replace(')', '')\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Had their chocolate almond croissant and it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
       "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
       "3  IXvOzsEMYtiJI0CARmj77Q  bv2nCi5Qv5vroFiqKGopiw  ACFtxLv8pGrrxMm6EgjreA   \n",
       "4  L_9BTb55X0GDtThi6GlZ6w  bv2nCi5Qv5vroFiqKGopiw  s2I_Ni76bjJNK9yG60iD-Q   \n",
       "\n",
       "   stars        date                                               text  \\\n",
       "0      5  2016-05-28  Super simple place but amazing nonetheless. It...   \n",
       "1      5  2016-05-28  Small unassuming place that changes their menu...   \n",
       "2      5  2016-05-28  Lester's is located in a beautiful neighborhoo...   \n",
       "3      4  2016-05-28  Love coming here. Yes the place always needs t...   \n",
       "4      4  2016-05-28  Had their chocolate almond croissant and it wa...   \n",
       "\n",
       "   useful  funny  cool  \n",
       "0       0      0     0  \n",
       "1       0      0     0  \n",
       "2       0      0     0  \n",
       "3       0      0     0  \n",
       "4       0      0     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df = pd.read_csv('yelp_review1.csv',nrows =10000)\n",
    "yelp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['review_id', 'user_id', 'business_id', 'stars', 'date', 'text', 'useful', 'funny', 'cool']\n"
     ]
    }
   ],
   "source": [
    "print(list(yelp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose text and star two colmns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(t, star) for t,star in zip(yelp_df['text'], yelp_df['stars'])]\n",
    "save_documents = open('documents.pickle',\"wb\")\n",
    "pickle.dump(documents, save_documents)\n",
    "save_documents.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This nonsense. I hate place. The food bad service terrible\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    " \n",
    "data = \"This is nonsense. I hate this place. The food is bad and the service is terrible\"\n",
    "stopWords = list(set(stopwords.words('english')))\n",
    "\n",
    "# stopWords[:5]\n",
    "print(' '.join([w for w in data.split() if w not in stopWords ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'python', 'python', 'python', 'pythonli']\n"
     ]
    }
   ],
   "source": [
    "# Use the stemmer to stem all the words\n",
    "ps = PorterStemmer()\n",
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]\n",
    "\n",
    "print([ps.stem(w) for w in example_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all occurrences of words and record the number of occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 65354), ('and', 44737), ('a', 36044), ('i', 34420), ('to', 30637), ('wa', 22561), ('of', 20322), ('it', 18047), ('is', 15896), ('for', 15601), ('in', 14641), ('with', 11745), ('my', 11421), ('that', 11393), ('but', 10306)]\n",
      "good appeared: 5827 times\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "\n",
    "for (t, star) in documents:\n",
    "    for word in t.split():\n",
    "        w = clean_format(word)\n",
    "        all_words.append(ps.stem(w))\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)\n",
    "print(all_words.most_common(15))\n",
    "print(\"good appeared: \" + str(all_words['good']) + \" times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_features = [s for (s,_) in list(all_words.most_common(5000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'a', 'i', 'to', 'wa', 'of', 'it', 'is', 'for']\n"
     ]
    }
   ],
   "source": [
    "print(words_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'a': True, 'but': True, \"30'\": False, 'help': True, 'bologna': False, 'sinc': True, 'veri': True, 'simpl': True, 'been': True, 'around': True, 'with:': False, 'amaz': True, 'mustard': True, 'serv': True, 'salami': True, 'with': True, \"it'\": True, 'the': True, 'they': True, 'nonetheless': True, 'friendli': True, 'wa': True, 'staff': True, 'place': True, 'super': True, 'same': True, 'thing': True, 'start': True, 'still': True, 'and': True, 'sandwich': True}, 5)\n"
     ]
    }
   ],
   "source": [
    "def find_features(document):\n",
    "    words = set(document.split())\n",
    "    features = {}\n",
    "    for w in words:\n",
    "        w = clean_format(w)\n",
    "        w = ps.stem(w)\n",
    "        features[w] = (w in words_features)\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(doc), star) for (doc,star) in documents]\n",
    "\n",
    "print(featuresets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos rate:  0.7870593915982617\n",
      "len of temp:  8284\n"
     ]
    }
   ],
   "source": [
    "# POS to NEG encode\n",
    "temp = []\n",
    "pos_count = 0\n",
    "for i in range(len(featuresets)):\n",
    "    if featuresets[i][1] >= 4:\n",
    "        temp.append((featuresets[i][0], 'pos'))\n",
    "        pos_count = pos_count + 1\n",
    "    elif featuresets[i][1] <= 2:\n",
    "        temp.append((featuresets[i][0], 'neg'))\n",
    "print(\"pos rate: \", pos_count / len(temp))\n",
    "print(\"len of temp: \", len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "2284\n"
     ]
    }
   ],
   "source": [
    "training_set = temp[:6000]\n",
    "testing_set = temp[6000:]\n",
    "\n",
    "print(len(training_set))\n",
    "print(len(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier accuracy:  42.16287215411559\n",
      "Most Informative Features\n",
      "                   worst = True              neg : pos    =     45.1 : 1.0\n",
      "                 disgust = True              neg : pos    =     44.2 : 1.0\n",
      "              underwhelm = True              neg : pos    =     31.2 : 1.0\n",
      "                   appal = True              neg : pos    =     28.7 : 1.0\n",
      "                 horrend = True              neg : pos    =     28.7 : 1.0\n",
      "                  poorli = True              neg : pos    =     27.7 : 1.0\n",
      "            unprofession = True              neg : pos    =     27.7 : 1.0\n",
      "              condescend = True              neg : pos    =     26.2 : 1.0\n",
      "                 downhil = True              neg : pos    =     24.7 : 1.0\n",
      "                    ined = True              neg : pos    =     20.2 : 1.0\n",
      "                    wors = True              neg : pos    =     19.7 : 1.0\n",
      "                  crappi = True              neg : pos    =     18.7 : 1.0\n",
      "                   crook = True              neg : pos    =     18.7 : 1.0\n",
      "                indiffer = False             neg : pos    =     18.7 : 1.0\n",
      "                 sarcast = True              neg : pos    =     18.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4747)\n",
    "\n",
    "clf = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Naive Bayes Classifier accuracy: \", nltk.classify.accuracy(clf, testing_set) * 100)\n",
    "clf.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 42.16287215411559\n",
      "Most Informative Features\n",
      "                   worst = True              neg : pos    =     45.1 : 1.0\n",
      "                 disgust = True              neg : pos    =     44.2 : 1.0\n",
      "              underwhelm = True              neg : pos    =     31.2 : 1.0\n",
      "                   appal = True              neg : pos    =     28.7 : 1.0\n",
      "                 horrend = True              neg : pos    =     28.7 : 1.0\n",
      "                  poorli = True              neg : pos    =     27.7 : 1.0\n",
      "            unprofession = True              neg : pos    =     27.7 : 1.0\n",
      "              condescend = True              neg : pos    =     26.2 : 1.0\n",
      "                 downhil = True              neg : pos    =     24.7 : 1.0\n",
      "                    ined = True              neg : pos    =     20.2 : 1.0\n",
      "                    wors = True              neg : pos    =     19.7 : 1.0\n",
      "                  crappi = True              neg : pos    =     18.7 : 1.0\n",
      "                   crook = True              neg : pos    =     18.7 : 1.0\n",
      "                indiffer = False             neg : pos    =     18.7 : 1.0\n",
      "                 sarcast = True              neg : pos    =     18.7 : 1.0\n",
      "MNB_classifier accuracy percent: 86.20840630472854\n",
      "BernoulliNB_classifier accuracy percent: 82.31173380035027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy percent: 91.24343257443083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_classifier accuracy percent: 89.88616462346761\n",
      "PolySVC_classifier accuracy percent: 83.53765323992994\n",
      "RadialSVC_classifier accuracy percent: 89.31698774080562\n",
      "SGDClassifier accuracy percent: 90.06129597197898\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4747)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "###############\n",
    "save_classifier = open('originalnaivebayes5k.pickle',\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"MNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(MNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"BernoulliNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"LogisticRegression_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LogisticRegression_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"LinearSVC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LinearSVC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "PolySVC_classifier = SklearnClassifier(SVC(kernel = 'poly'))\n",
    "PolySVC_classifier.train(training_set)\n",
    "print(\"PolySVC_classifier accuracy percent:\", (nltk.classify.accuracy(PolySVC_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"PolySVC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(PolySVC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "RadialSVC_classifier = SklearnClassifier(SVC(kernel = 'rbf'))\n",
    "RadialSVC_classifier.train(training_set)\n",
    "print(\"RadialSVC_classifier accuracy percent:\", (nltk.classify.accuracy(RadialSVC_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"RadialSVC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(RadialSVC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "#NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "#NuSVC_classifier.train(training_set)\n",
    "#print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "#save_classifier = open(\"NuSVC_classifier5k.pickle\",\"wb\")\n",
    "#pickle.dump(LinearSVC_classifier, save_classifier)\n",
    "#save_classifier.close()\n",
    "\n",
    "SGDC_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDC_classifier.train(training_set)\n",
    "print(\"SGDClassifier accuracy percent:\",nltk.classify.accuracy(SGDC_classifier, testing_set)*100)\n",
    "\n",
    "save_classifier = open(\"SGDC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(SGDC_classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voted_classifier accuracy percent: 90.8493870402802\n"
     ]
    }
   ],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        chosen_class = votes.count(mode(votes))\n",
    "        return chosen_class / len(votes)\n",
    "    \n",
    "voted_classifier = VoteClassifier(MNB_classifier,\n",
    "                                  LogisticRegression_classifier, \n",
    "                                  LinearSVC_classifier) \n",
    "#                                   MNB_classifier, \n",
    "#                                   NuSVC_classifier)\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    return voted_classifier.classify(feats),voted_classifier.confidence(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', 1.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"This place is awesome! Definitely recommend it to friends. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', 0.6666666666666666)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"This restaurant is terrible. The service was bad. The food was not delicious.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
